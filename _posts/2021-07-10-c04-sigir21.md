---
title: "Understanding the Role of Affect Dimensions in Detecting Emotions from Tweets: A Multi-task Approach"
date: 2021-07-10
permalink: posts/2021/07-c04-sigir21 #/publication/c04 
excerpt_separator: <!--more-->
toc: true
gallery:
  - url: posts/c04-sigir21/ekman.png
    image_path: posts/c04-sigir21/ekman.png
    alt: "Ekman's 6 Basic Emotions"
    title: "Ekman's 6 Basic Emotions"
  - url: posts/c04-sigir21/plutchik.png
    image_path: posts/c04-sigir21/plutchik.png
    alt: "Plutchik's Wheel of Emotions"
    title: "Plutchik's Wheel of Emotions"
gallery1:
  - url: posts/c04-sigir21/vad-components.png
    image_path: posts/c04-sigir21/vad-components.png
    alt: "VAD Components"
    title: "VAD Components"
  - url: posts/c04-sigir21/vad-architecture2.png
    image_path: posts/c04-sigir21/vad-architecture2.png
    alt: "VAD Architecture"
    title: "VAD Architecture"
tags:
  - sigir
  - emotion analysis
  - pshychology
  - dimensional models
  - categorical models
---

<!--more-->
<b>Rajdeep Mukherjee</b>, Atharva Naik, Sriyash Poddar, Soham Dasgupta, <a href="http://www.facweb.iitkgp.ac.in/~niloy/">Niloy Ganguly</a>

# TLDR

<ul>
  <li> Identifying author's emotions from written narratives is a challenging task. </li>
  <li> Psychological Theories of Emotion - <i> Categorical </i> (cognitively simpler) Vs <i> Dimensional </i> (fundamentally stronger) </li>
  <li> We propose a solution that exploits the strong correlation between the two models of emotion representation to efficiently detect emotions from tweets. </li>
</ul>

[Paper](/files/pdf/research/c04.pdf){: .btn--research} [Code](https://github.com/atharva-naik/VADEC/){: .btn--research} [Poster](/files/pdf/research/VADEC_SIGIR2021_Poster.pdf){: .btn--research} [Slides](https://docs.google.com/presentation/d/e/2PACX-1vQpnzCkBpsfsG5ah-KKegGFc90IwTHZiLkzB76kUXlrmrz7m-6JnWl3-uTfoFs-LsNVbmPE2JqAXdHT/pub?start=false&loop=false&delayms=3000){: .btn--research} [Video](https://files.atypon.com/acm/a419079f7fed8d5a4e1e8cf5553b7139){: .btn--research} [Citation](https://dl.acm.org/doi/10.1145/3404835.3463080){: .btn--research}

# Overview

Human emotions are characterized by how we react to various events. They play a central role in our understanding and descriptions of the world around us. Detecting emotions from short texts, especially tweets, is a crucial task
given its widespread applications in e-commerce, public health monitoring, stock market analysis, disaster management, etc. Understanding the nuances and complexities of human emotions is challenging and has therefore given rise to one of the most pressing debates among researchers on how best to represent emotions. Traditionally, the field of psychology has been dominated by two <i> seemingly opposing </i> theories of emotion, with their own set of supporters: a <i> Categorical </i> theory and a <i> Dimensional <i> theory.

![](/images/posts/c04-sigir21/catDim.png){: .align-center }

## Categorical Theory

Categorical models of emotion representation classify affective states into discrete categories. Two of the most popular models across literature are Ekman's <i>Basic Emotions</i> model, and <i>Plutchik's Wheel of Emotions</i>. In 1992, Paul Ekman proposed the existence of <b> six </b> <i>basic</i>, distinct, and universal emotions: happiness, anger, sadness, surprise, disgust, and fear. In 1980, Robert Plutchik created the <i>Emotion Wheel</i> that provides a great framework for understanding an emotion and its purpose. The wheel is divided into <b> eight </b> sectors corresponding to eight primary emotions: joy, trust, fear, surprise, sadness, anticipation, anger, and disgust. Each primary emotion has a polar opposite based on the physiological reaction it creates. Further, the emotions intensify as they move from the outside to the center of the wheel, which is also indicated by the color: the darker the shade, the more intense the emotion.

{% include gallery %}

Humans can however perceive hundreds of different emotions. While the categorical models are cognitively more suitable to work with, they have a limited scope. Also, it is almost infeasible to create datasets annotated for the presence/absence of hundreds of different emotions. <i> How can we capture a broader range of affective states? </i>

## Dimensional Theory

Dimensional models come to the rescue as they conceptualize human emotions by defining where they lie in a 2- or 3-dimensional space created by shared underlying <i>affect dimensions</i>. One of the popular models in this category is the Russel and Mehrabianâ€™s <i>Valence-Arousal-Dominance </i>(VAD) model. It interprets emotions as points in a 3-D space with <i>Valence</i> (degree of pleasure or displeasure), <i>Arousal</i> (degree of calmness or excitement), and <i>Dominance</i> (degree of authority or submission) being the three orthogonal dimensions.

![](/images/posts/c04-sigir21/vad.png){: .align-center }

Overall, we see that <i>dimensional</i> models are fundamentally more powerful as they can capture all possible emotions in terms of varying degrees of affect dimensions. However, it's very difficult to obtain a perfect mapping between all possible emotions and their corresponding V, A, and D scores owing to several considerations such as feasibility, cultural differences, etc. <i>Categorical</i> analysis on the other hand is cognitively more suitable for humans to make the final inferences for various downstream applications. For e.g., it is easier to infer that a person is <i>depressed</i> or <i>happy</i> rather than contemplating about the scores obtained for the underlying dimensions. 

Our goal therefore is to build a system that efficiently detects emotion categories from textual narratives, and the question that we investigate in this [work](/files/pdf/research/c04.pdf) is whether V-A-D supervisions can improve the emotion classification (EC) performance.

## Are The Two Theories Connected?

In order to understand the correlation between the two models of emotion representation, let us consider the sentence "I was so excited to be a part of this team! What a win!". Clearly, the author of the sentence is very <i>Happy</i> or <i>Joyous</i> (Remember Ekman?). Further, we observe that words that evoke some kind of emotion such as `excited` and `win` carry scores along multiple affect dimensions. The same is true for the context of the sentence (for eg., consider `win` vs `What a win!`). The word `so` on the other hand suggests a high <i>Arousal</i> score.

![](/images/posts/c04-sigir21/relation.png){: .align-center }

Now, what happens if we modify the original sentence by replacing `win` with `lost`? The scores along the <i>Valence</i> and <i>Dominance</i> dimensions immediately come down thereby changing the overall emotion expressed in the sentence from <i>Happy</i> to <i>Neutral</i>. Why neutral? Because, the first part of the sentence still evokes a positive sentiment. Hence, we find that there is a direct correlation between the two theories and this is what we take our motivation from.


# Our Proposal: VADEC

We utilize the better representational power of dimensional models to improve the emotion classification performance by proposing
<i><b>VADEC</b></i>, that co-trains multi-label emotion classification (i.e. the <i>Classifier</i> module) and multi-dimensional emotion regression (i.e. the <i>Regressor</i> module) by jointly optimizing the weights of a shared text-encoder, based on <i>BERTweet</i>, which is a <i>RoBERTa</i>-based architecture pre-trained on millions of tweets. 

{% include gallery1 %}

In order to understand the advantage of taking a multi-task approach, we compare the performance of <i>VADEC</i> with those of <i><b>EC</b></i> and <i><b>VADR</b></i>, respectively representing the <i>Classifier</i> and <i>Regressor</i> modules when trained independently. Please refer to the [paper](/files/pdf/research/c04.pdf) for complete details.


# Results: VAD helps EC

For our experiments, we consider <i><b>EmoBank</b></i>: a VAD dataset, consisting of around 10K sentences annotated with continuous scores for Valence, Arousal, and Dominance dimensions of the text. In order to demonstrate the utility of our proposed approach, we consider two <i>categorical</i> datasets (each to be used separately with <i>EmoBank</i> for co-training) - <i><b>AIT</b></i> (<i>Affect in Tweets</i>): a SemEval 2018 dataset consisting of 10,983 English tweets annotated for the presence/absence of 11 general emotions, and <i><b>SenWave</b></i>: consisting 10K tweets annotated for the presence/absence of 11 emotions specific to COVID-19.

![](/images/posts/c04-sigir21/EC_results.png){: .align-center }

For our primary task of <i>Multi-label Emotion Classification</i>> we obtain better results with <i>VADEC</i> on both <i>AIT</i> as well as <i>SenWave</i>, thereby demonstrate the advantage of exploiting VAD supervisions for the task.

![](/images/posts/c04-sigir21/VAD_results.png){: .align-center }

Joint-learning does not however help the <i>Multi-dimensional Regression</i> task as much as it helps in improving the classification
performance, which in fact is our main objective. Still, we achieve noticeable improvements over the baselines for 2/3 emotion dimensions.


# Summary

We show that the performance of emotion recognition in written narratives, especially tweets, can be improved by utilizing the better representational power of the dimensional models of emotion representation.